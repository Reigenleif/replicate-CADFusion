# Token configurations
HF_TOKEN=hf_example
WANDB_API_KEY=wandb_v1_example

# Inference Base URL
INFERENCE_BASE_URL=http://localhost:11434/v1

# Model IDs
PREPROCESSING_VLM_MODEL_ID=llama3.2:1b
MAIN_MODEL_ID=meta-llama/Llama-3.2-1B-Instruct
DPO_VLM_MODEL_ID=llama3.2:1b

